{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Gemini Setup"
      ],
      "metadata": {
        "id": "6UWLjEF4NMeP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBQDlaJnF_kE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from flask import Flask, request, jsonify\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.api_core import retry\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Get API Key\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if not GOOGLE_API_KEY:\n",
        "    GOOGLE_API_KEY = input(\"Please enter your Google API key: \")\n",
        "if not GOOGLE_API_KEY:\n",
        "    raise ValueError(\"Google API key not found. Please set the GOOGLE_API_KEY environment variable or provide it manually.\")\n",
        "\n",
        "# Initialize GenAI client\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Retry policy for quota or service limit errors\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "if not hasattr(genai.models.Models.generate_content, '_wrapped_'):\n",
        "    genai.models.Models.generate_content = retry.Retry(predicate=is_retriable)(\n",
        "        genai.models.Models.generate_content\n",
        "    )\n",
        "\n",
        "# Enable grounding via Google Search\n",
        "config_with_search = types.GenerateContentConfig(\n",
        "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        ")\n",
        "\n",
        "# Shared memory\n",
        "conversation_history = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini Chatbot function for MCP\n"
      ],
      "metadata": {
        "id": "_SHnGNZZOBWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gemini_reply(user_input):\n",
        "    conversation_history.append(types.Content(role=\"user\", parts=[types.Part(text=user_input)]))\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=conversation_history,\n",
        "        config=config_with_search,\n",
        "    )\n",
        "    reply_text = response.candidates[0].content.parts[0].text\n",
        "    conversation_history.append(types.Content(role=\"model\", parts=[types.Part(text=reply_text)]))\n",
        "    return reply_text"
      ],
      "metadata": {
        "id": "1F_K0KN4GdlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP Webhook Endpoint"
      ],
      "metadata": {
        "id": "J_609fEVOKMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/mcp_webhook', methods=['POST'])\n",
        "def mcp_webhook():\n",
        "    data = request.json\n",
        "    user_id = data.get(\"from\")\n",
        "    user_text = data.get(\"message\", {}).get(\"text\")\n",
        "\n",
        "    if not user_id or not user_text:\n",
        "        return jsonify({\"error\": \"Invalid message format\"}), 400\n",
        "\n",
        "    try:\n",
        "        reply = get_gemini_reply(user_text)\n",
        "        send_reply_to_mcp(user_id, reply)\n",
        "        return jsonify({\"status\": \"success\"}), 200\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500"
      ],
      "metadata": {
        "id": "AD1VMYUfGi5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send Reply Back to MCP"
      ],
      "metadata": {
        "id": "LyBG_rkkOOmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def send_reply_to_mcp(user_id, text):\n",
        "    MCP_API_URL = \"https://api.gupshup.io/sm/api/v1/msg\"  # Replace with your MCP send URL\n",
        "    MCP_TOKEN = os.getenv(\"MCP_API_TOKEN\") or \"Write MCP token here\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {MCP_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"to\": user_id,\n",
        "        \"message\": {\"text\": text}\n",
        "    }\n",
        "\n",
        "    response = requests.post(MCP_API_URL, json=payload, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to send MCP message: {response.text}\")"
      ],
      "metadata": {
        "id": "kh_Jw9t0HCy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLI Chatbot Loop"
      ],
      "metadata": {
        "id": "_w8Aos7wOU0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Chatbot with memory and search grounding started! Type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Exiting the chatbot. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    conversation_history.append(types.Content(role=\"user\", parts=[types.Part(text=user_input)]))\n",
        "\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=conversation_history,\n",
        "            config=config_with_search,\n",
        "        )\n",
        "        reply_text = response.candidates[0].content.parts[0].text\n",
        "        display(Markdown(reply_text))\n",
        "        conversation_history.append(types.Content(role=\"model\", parts=[types.Part(text=reply_text)]))\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)"
      ],
      "metadata": {
        "id": "KecBA4YAIuMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flask App Run Block"
      ],
      "metadata": {
        "id": "FB0SiCXAOZez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "id": "Ka382oHWLMKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}